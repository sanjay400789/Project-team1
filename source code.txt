from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import gradio as gr
# Load the dataset
df = pd.read_csv("MedAI.csv")
df.head()
print("Shape:", df.shape)
print("Columns:", df.columns)
print(df.info())
print(df.isnull().sum())
# Check for missing values in each column
print("üîç Missing Values per Column:")
print(df.isnull().sum())
# Check for total number of duplicate rows
print("\nüîÅ Number of Duplicate Rows:")
print(df.duplicated().sum())
import seaborn as sns
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt

# Display inline plots
%matplotlib inline

# Check your column names to adjust if needed
print("Columns:", df.columns.tolist())

# Set a nice style
sns.set(style="whitegrid")

# 1. Disease Distribution
plt.figure(figsize=(8, 4))
sns.countplot(x='Disease', data=df)
plt.title('Distribution of Diseases')
plt.xticks(rotation=45)
plt.show()

# 2. Age vs Disease
if 'Age' in df.columns:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x='Disease', y='Age', data=df)
    plt.title('Age Distribution by Disease')
    plt.xticks(rotation=45)
    plt.show()

# 3. BloodPressure vs Disease
if 'BloodPressure' in df.columns:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x='Disease', y='BloodPressure', data=df)
    plt.title('Blood Pressure vs Disease')
    plt.xticks(rotation=45)
    plt.show()

# 4. Cholesterol vs Disease
if 'Cholesterol' in df.columns:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x='Disease', y='Cholesterol', data=df)
    plt.title('Cholesterol vs Disease')
    plt.xticks(rotation=45)
    plt.show()

# 5. Gender-based Disease Count
if 'Gender' in df.columns:
    plt.figure(figsize=(8, 4))
    sns.countplot(x='Disease', hue='Gender', data=df)
    plt.title('Disease Distribution by Gender')
    plt.xticks(rotation=45)
    plt.show()

# 6. Correlation Heatmap (numerical features only)
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title('Feature Correlation Heatmap')
plt.show()
# Define the target column (update this if your actual target column name is different)
target = 'Disease'

# Get feature columns (all columns except the target)
features = df.columns.drop(target)

# Display them
print("üéØ Target Variable:", target)
print("üß© Feature Columns:", features.tolist())
# Identify categorical columns
categorical_cols = df.select_dtypes(include=['object']).columns
print("üß† Categorical Columns:", categorical_cols.tolist())

# Convert categorical columns using one-hot encoding
df_encoded = pd.get_dummies(df, drop_first=True)

# Show shape and sample
print("‚úÖ Encoded DataFrame shape:", df_encoded.shape)
df_encoded.head()
drop_first=True
df_encoded = pd.get_dummies(df, drop_first=True)
# Select only numerical columns
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns

# Handle missing values if any
df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())

# Initialize scaler
scaler = StandardScaler()

# Apply scaling
df_scaled = pd.DataFrame(scaler.fit_transform(df[numerical_cols]), columns=numerical_cols)

# Save scaled data
df_scaled.to_csv('MedAI_feature_scaled.csv', index=False)
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
# Train model
model = LinearRegression()
model.fit(X_train, y_train)
# Predict
y_pred = model.predict(X_test)
print("MSE:", mean_squared_error(y_test, y_pred))
print("R¬≤ Score:", r2_score(y_test, y_pred))
# Example input (your new student)
new_student = {
    'school': 'GP', 'sex': 'F', 'age': 17, 'address': 'U', 'famsize': 'GT3', 'Pstatus': 'A',
    'Medu': 4, 'Fedu': 3, 'Mjob': 'health', 'Fjob': 'services', 'reason': 'course', 'guardian': 'mother',
    'traveltime': 2, 'studytime': 3, 'failures': 0, 'schoolsup': 'yes', 'famsup': 'no', 'paid': 'no',
    'activities': 'yes', 'nursery': 'yes', 'higher': 'yes', 'internet': 'yes', 'romantic': 'no',
    'famrel': 4, 'freetime': 3, 'goout': 3, 'Dalc': 1, 'Walc': 1, 'health': 4, 'absences': 2,
    'G1': 14, 'G2': 15
}
new_student_df = pd.DataFrame([new_student])
print(new_student_df)
def predict_target(input_dict):
    processed_input = encode_input(input_dict)
    prediction = model.predict(processed_input)[0]
    return f"Predicted Class: {prediction}"
!pip install gradio
# üì¶ Step 1: Install Required Libraries
!pip install -q pandas scikit-learn joblib

# üìÇ Step 2: Upload the Dataset
from google.colab import files
uploaded = files.upload()

import pandas as pd

# Load dataset (make sure the filename matches your upload)
df = pd.read_csv("MedAI.csv")
df.head()
# üßπ Step 3: Preprocess Data

# Example: Assume last column is the target
X = df.iloc[:, :-1]  # Features
y = df.iloc[:, -1]   # Target

# Optional: Feature scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# ü§ñ Step 4: Train a Model
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

model = RandomForestClassifier()
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
# üíæ Step 5: Save the Model and Scaler
import joblib

joblib.dump(model, "medai_model.pkl")
joblib.dump(scaler, "medai_scaler.pkl")
# üß† Step 6: Create the Prediction Function

# Load the model and scaler
model = joblib.load("medai_model.pkl")
scaler = joblib.load("medai_scaler.pkl")

# Get feature names
feature_names = list(df.columns[:-1])

# Define the prediction function
def predict_medical_condition(*inputs):
    input_array = pd.DataFrame([inputs], columns=feature_names)
    input_scaled = scaler.transform(input_array)
    prediction = model.predict(input_scaled)[0]
    proba = model.predict_proba(input_scaled).max()
    return f"Prediction: {prediction} (Confidence: {proba:.2f})"
!pip install -q gradio
import gradio as gr
import joblib
import pandas as pd

# Load model and scaler
model = joblib.load("medai_model.pkl")
scaler = joblib.load("medai_scaler.pkl")

# Define the feature names based on your dataset
feature_names = ['Age', 'BMI', 'BloodPressure', 'Glucose', 'Insulin']  # Replace with your real features

# Prediction function
def predict_medical_condition(age, bmi, bp, glucose, insulin):
    input_data = pd.DataFrame([[age, bmi, bp, glucose, insulin]], columns=feature_names)
    input_scaled = scaler.transform(input_data)
    prediction = model.predict(input_scaled)[0]
    confidence = model.predict_proba(input_scaled).max()
    return f"Prediction: {prediction} (Confidence: {confidence:.2f})"
# Create the Gradio Interface
interface = gr.Interface(
    fn=predict_medical_condition,
    inputs=[
        gr.Number(label="Age"),
        gr.Number(label="BMI"),
        gr.Number(label="Blood Pressure"),
        gr.Number(label="Glucose"),
        gr.Number(label="Insulin"),
    ],
    outputs="text",
    title="ü©∫ Medical Condition Predictor",
    description="Enter the patient's metrics to predict a medical condition."
)

# Launch the interface
interface.launch(share=True)
